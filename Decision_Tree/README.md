[DecisionTree:决策树]
-----
<br>
决策树是机器学习中最容易理解的算法之一，但决策树的实现并不容易<br>
同时，由决策树桩和CART树构成的集成学习方法（如GBDT、xGBoost、RF等）深受数据挖掘竞赛青睐<br>
本节中我会详细构造ID3、C4.5、CART决策树，并详细讲解决策树在不同情况下的使用<br>
以及一些特殊情况，如缺失值、连续值、树回归等<br>
同时，决策树一般不需要对数据预处理，而且处理离散属性非常合适<br>
也是为数不多可以同时处理离散属性和连续属性的机器学习算法<br>
<br>
<br>
<br>
决策树一般算法的步骤如下：<br>
<br>
1.计算当前数据集的熵／基尼因数<br><br>
2.依次尝试用所有特征划分数据集，计算划分之后的信息增益／增益比／基尼因数<br><br>
3.选取最好的特征划分数据集<br><br>
4.如果未达到终止条件，对所有子集合重复1-3<br><br>
5.决策树剪枝（预剪枝、后剪枝）<br><br>
<br>
<br>
＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝<br>
目前已更新：<br><br>
1.ID3决策树<br><br>
<br>
---持续更新中---<br><br>
<br>
<br>
<br>
tips:<br>
foxmail：  zixuwang1997@foxmail.com<br>
gamil:     zixuwang1997@gmail.com<br>
others:    zixuwang@csu.edu.cn<br>
